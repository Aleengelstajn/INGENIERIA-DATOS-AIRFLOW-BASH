{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer clouster sampling para modelo de maching learning.\n",
    "Variables de bloqueo:\n",
    "    * Mes\n",
    "    * Dia\n",
    "    * hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import warnings # Para liminar warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos todos los set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(ruta = \"./Datasets/taxi_trip\"):\n",
    "    return [arch.name for arch in os.scandir(ruta) if arch.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2017-06.parquet',\n",
       " 'yellow_tripdata_2017-07.parquet',\n",
       " 'yellow_tripdata_2017-08.parquet',\n",
       " 'yellow_tripdata_2017-09.parquet',\n",
       " 'yellow_tripdata_2017-10.parquet',\n",
       " 'yellow_tripdata_2017-11.parquet',\n",
       " 'yellow_tripdata_2017-12.parquet',\n",
       " 'yellow_tripdata_2018-01.parquet']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_parquet('datasets/output_2018-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading…: 100%|███████████████████████████| 8/8 [2:03:58<00:00, 929.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# indice en la muestra\n",
    "collection = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "    \n",
    "    # crear dataframe vacio para el sample\n",
    "    muestra = pd.DataFrame()\n",
    "    # Creamos las columnas del dataframe\n",
    "    for i in f:\n",
    "        muestra[i] = i\n",
    "\n",
    "    # CODIGO PARA CREAR SAMPLES DE LOS N ARCHIVOS\n",
    "\n",
    "    for file in tqdm (archivos, desc=\"Loading…\", ascii=False, ncols=75):\n",
    "\n",
    "        \n",
    "        # --------------------CODIGO NECESARIO PARA CREAR EL SAMPLE---------------------------\n",
    "        date = re.findall(r'\\S*([0-9][0-9][0-9][0-9]-[0-9][0-9]).parquet', file)\n",
    "        \n",
    "        # Directorio para los archivos\n",
    "        ruta = 'datasets/taxi_trip/yellow_tripdata_'+date[0]+'.parquet'\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Obtener cota de los meses\n",
    "        final_date = date[0]+'-01'\n",
    "        date = date[0].split('-')\n",
    "        execution_date = datetime.datetime(int(date[0]), int(date[1]), 1)\n",
    "        final_date = execution_date + datetime.timedelta(days = pd.Period(final_date).days_in_month )\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Cargamos dataset\n",
    "        df = pd.read_parquet(ruta)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # eliminamos registros con fechas diferentes al mes en cuestion con base en la cota de los meses\n",
    "        df.drop(df[df['tpep_pickup_datetime'] > final_date].index, inplace = True)\n",
    "        df.drop(df[df['tpep_pickup_datetime'] < execution_date].index, inplace = True)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # creamos la mask para un dia y la hora\n",
    "        mask_dia = np.zeros((df.tpep_pickup_datetime.shape[0], 1))\n",
    "        mask_hora = np.zeros((df.tpep_pickup_datetime.shape[0], 1))\n",
    "    \n",
    "        for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "            mask_dia[idx] =  i.strftime(\"%d\")\n",
    "        \n",
    "        for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "            mask_hora[idx] =  i.strftime(\"%H\")\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Creamos los arrays en los que vamos a iterar\n",
    "        dias = np.unique(mask_dia)\n",
    "        horas = np.unique(mask_hora)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Ajustamos las mascaras para poder usarlas\n",
    "        mask_dia = mask_dia.sum(axis=1)\n",
    "        mask_hora = mask_hora.sum(axis=1)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Obtenemos la muestra\n",
    "        for d in dias:\n",
    "            for h in horas:    \n",
    "                # dataframe filtrando por dia y hora\n",
    "                aux = df[(mask_dia == d) & (mask_hora == h)]\n",
    "        \n",
    "                # obtenemos la muestra aleatoria del 12.5% de los datos\n",
    "                mu = aux.sample(frac =.125)\n",
    "        \n",
    "                # Concatenamos mu con la muestra\n",
    "                muestra = muestra.append(mu)\n",
    "                del mu\n",
    "                del aux\n",
    "\n",
    "            #print('Dia '+str(d)+' finalizado')\n",
    "    \n",
    "    collection.append(muestra)\n",
    "    del df\n",
    "    del muestra\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.concat(collection, axis=0)\n",
    "new = new.reset_index()\n",
    "new.drop(columns='index',inplace=True)\n",
    "new.to_parquet('8_months_taxi.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra.to_csv('5_months_taxi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas que hice para construir la funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_trip import outliers_obt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indice en la muestra\n",
    "collection = []\n",
    "idx = 0\n",
    "\n",
    "# DataFrame resultante\n",
    "# columnas\n",
    "col = ['date','trips','total_amount_sum','total_amount_mean','trip_distance_sum','trip_distance_mean']\n",
    "muestra = pd.DataFrame()\n",
    "for i in col:\n",
    "    muestra[i] = i\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "    # DataFrame resultante\n",
    "    muestra = pd.DataFrame()\n",
    "    for i in f:\n",
    "        muestra[i] = i\n",
    "\n",
    "\n",
    "    for file in tqdm (archivos, desc=\"Loading…\", ascii=False, ncols=75):\n",
    "        date = re.findall(r'\\S*([0-9][0-9][0-9][0-9]-[0-9][0-9]).parquet', file)\n",
    "        \n",
    "        # Directorio para los archivos\n",
    "        ruta = 'datasets/taxi_trip/yellow_tripdata_'+date[0]+'.parquet'\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "        # Obtener cota de los meses\n",
    "        final_date = date[0]+'-01'\n",
    "        date = date[0].split('-')\n",
    "        execution_date = datetime.datetime(int(date[0]), int(date[1]), 1)\n",
    "        final_date = execution_date + datetime.timedelta(days = pd.Period(final_date).days_in_month - 1)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Cargamos dataset\n",
    "        df = pd.read_parquet(ruta)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # eliminamos registros con fechas diferentes a enero del 2018\n",
    "        df.drop(df[df['tpep_pickup_datetime'] > final_date].index, inplace = True)\n",
    "        df.drop(df[df['tpep_pickup_datetime'] < execution_date].index, inplace = True)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    ## NORMALIZACION\n",
    "    #('---------------------------------OUTLIERS---------------------------')\n",
    "        df=outliers_obt(df,'total_amount','0.25','0.75',valoriqr=4.5)\n",
    "        df=outliers_obt(df,'improvement_surcharge','0.25','0.75',valoriqr=4.5)\n",
    "        df=outliers_obt(df,'tip_amount','0.25','0.75',valoriqr=2)\n",
    "        df=outliers_obt(df,'mta_tax','0.25','0.75',valoriqr=1.5)\n",
    "        df=outliers_obt(df,'extra','0.25','0.75',valoriqr=1.5)\n",
    "        df=outliers_obt(df,'fare_amount','0.25','0.75',valoriqr=4.5)\n",
    "        df=outliers_obt(df,'trip_distance','0.25','0.75',valoriqr=3)\n",
    "        df=outliers_obt(df,'tpep_dropoff_datetime','0.25','0.75',valoriqr=1.5)\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Drop columns\n",
    "        df = df[['trip_distance','total_amount']].copy()\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # creamos la mask para un dia y la hora\n",
    "        mask_dia = np.zeros((df.tpep_pickup_datetime.shape[0], 1))\n",
    "        #mask_hora = np.zeros((df.tpep_pickup_datetime.shape[0], 1))\n",
    "    \n",
    "        for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "            mask_dia[idx] =  i.strftime(\"%d\")\n",
    "        \n",
    "        #for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "        #    mask_hora[idx] =  i.strftime(\"%H\")\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Creamos los arrays en los que vamos a iterar\n",
    "        dias = np.unique(mask_dia)\n",
    "        #horas = np.unique(mask_hora)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Ajustamos las mascaras para poder usarlas\n",
    "        mask_dia = mask_dia.sum(axis=1)\n",
    "        #mask_hora = mask_hora.sum(axis=1)\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # Obtenemos la muestra\n",
    "        for d in tqdm (dias, desc=\"Loading…\", ascii=False, ncols=75):\n",
    "            # declaramos row\n",
    "            row = []\n",
    "            #for h in horas:    \n",
    "            # dataframe filtrando por dia y hora\n",
    "            #aux = df[mask_dia == d].copy()\n",
    "            # dia\n",
    "            fecha = datetime.datetime(int(date[0]), int(date[1]), d)\n",
    "            \n",
    "            # obtenemos las columnas\n",
    "            row.append(fecha)\n",
    "            row.append(df[mask_dia == d].shape[0])\n",
    "            row.append(df[mask_dia == d].total_amount.sum())\n",
    "            row.append(df[mask_dia == d].total_amount.median())\n",
    "            row.append(df[mask_dia == d].trip_distance.sum())\n",
    "            row.append(df[mask_dia == d].trip_distance.median())\n",
    "    \n",
    "            # Concatenamos mu con la muestra\n",
    "            muestra.loc[idx] = row\n",
    "            #print('Dia '+str(d)+' finalizado')\n",
    "    \n",
    "    collection.append(muestra)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8821636 entries, 4145 to 8433068\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype \n",
      "---  ------                 ----- \n",
      " 0   VendorID               object\n",
      " 1   tpep_pickup_datetime   object\n",
      " 2   tpep_dropoff_datetime  object\n",
      " 3   passenger_count        object\n",
      " 4   trip_distance          object\n",
      " 5   RatecodeID             object\n",
      " 6   store_and_fwd_flag     object\n",
      " 7   PULocationID           object\n",
      " 8   DOLocationID           object\n",
      " 9   payment_type           object\n",
      " 10  fare_amount            object\n",
      " 11  extra                  object\n",
      " 12  mta_tax                object\n",
      " 13  tip_amount             object\n",
      " 14  tolls_amount           object\n",
      " 15  improvement_surcharge  object\n",
      " 16  total_amount           object\n",
      " 17  congestion_surcharge   object\n",
      " 18  airport_fee            object\n",
      "dtypes: object(19)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "muestra.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos dataset\n",
    "df = pd.read_parquet('datasets/output_2018-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_date = datetime.datetime(2018, 1, 1)\n",
    "final_date = datetime.datetime(2018, 1, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos registros con fechas diferentes a enero del 2018\n",
    "df.drop(df[df['tpep_pickup_datetime'] > final_date].index, inplace = True)\n",
    "df.drop(df[df['tpep_pickup_datetime'] < execution_date].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir el dataframe por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la mask para un dia y la hora\n",
    "mask_dia = np.zeros((df.tpep_pickup_datetime.shape[0], 1))\n",
    "mask_hora = np.zeros((df.tpep_pickup_datetime.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "    #print(i)\n",
    "    #print(type(i.strftime(\"%d\")))\n",
    "    mask_dia[idx] =  i.strftime(\"%d\")\n",
    "    #print(mask_dia[idx])\n",
    "    \n",
    "for idx, i in enumerate(df.tpep_pickup_datetime):\n",
    "    mask_hora[idx] =  i.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los arrays en los que vamos a iterar\n",
    "dias = np.unique(mask_dia)\n",
    "horas = np.unique(mask_hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame resultante\n",
    "muestra = pd.DataFrame()\n",
    "for i in df:\n",
    "    muestra[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos las mascaras para poder usarlas\n",
    "mask_dia = mask_dia.sum(axis=1)\n",
    "mask_hora = mask_hora.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8441287,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tpep_pickup_datetime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "# Obtenemos la muestra\n",
    "for d in tqdm (dias, desc=\"Loading…\", ascii=False, ncols=75):\n",
    "    for h in horas:    \n",
    "        # dataframe filtrando por dia y hora\n",
    "        aux = df[(mask_dia == d) & (mask_hora == h)].copy()\n",
    "\n",
    "        # obtenemos la muestra aleatoria del 12.5% de los datos\n",
    "        mu = aux.sample(frac =.125)\n",
    "\n",
    "        # Concatenamos mu con la muestra\n",
    "        muestra = muestra.append(mu)\n",
    "        \n",
    "    print(d)\n",
    "    #print('Dia '+str(d)+' finalizado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading…: 100%|████████████████████████████| 31/31 [00:00<00:00, 63.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "for i in tqdm (dias,\n",
    "\t\t\tdesc=\"Loading…\",\n",
    "\t\t\tascii=False, ncols=75):\n",
    "\t#print(i)\n",
    "\ttime.sleep(0.01)\n",
    "\t\n",
    "print(\"Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89f8f4da03b88366b24b3e615f25203f75fc591e3c4bb5e4e10f1e65da1c83de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
